{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42c52592-6d9f-424e-aaf2-7ec91280028b",
   "metadata": {},
   "source": [
    "# Hotdog or not - Image recognition Model\n",
    "The main goal of projet is to create deep program for image recognition. In this case object objects to be recognized will be hot dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694094d3-ce99-4b3f-9199-4c83dfdfb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if compatible GPU is available \n",
    "from torch.cuda import is_available, get_device_name\n",
    "\n",
    "if is_available():\n",
    "    print(f\"The environment has a compatible GPU ({get_device_name()}) available.\")\n",
    "else:\n",
    "    print(\"The environment does NOT have a compatible GPU model available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "def imshow(inp: torch.Tensor) -> None:\n",
    "    '''Imshow for torch.Tensor'''\n",
    "    inp = inp.cpu().numpy()\n",
    "    inp = inp.transpose((1,2,0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std*inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import hot dog data\n",
    "import os\n",
    "from typing import Tuple\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from requests import get\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HotDogDataset(Dataset):\n",
    "    \"\"\"\"\n",
    "    Child class of torch.utlis.data.Dataset.\n",
    "    This is wrapper for mapping from hotdog/not images to the target.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dir_name, transform=None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize a HotdogDataset class\n",
    "        :param dir_name: The name of folder holding the data.\n",
    "        :param transform:\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        #Download, save and extract data if needed.\n",
    "        if not os.path.isdir(os.path.join(os.getcwd(), f\"{dir_name}\")):\n",
    "            r = get(f\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/hotdog-not-hotdog/data/{dir_name}.zip\")\n",
    "            f = open(os.path.join(os.getcwd(), f\"{dir_name}.zip\"), mode=\"wb+\")\n",
    "            f.write(r.content)\n",
    "            f.close()\n",
    "            with ZipFile(os.path.join(os.getcwd(), f\"{dir_name}.zip\"), 'r') as zip_ref:\n",
    "                zip_ref.extractall(\"./\")\n",
    "                zip_ref.close()\n",
    "        # Load metadata.\n",
    "        self.data = read_csv(os.path.join(os.getcwd(), dir_name, f\"{dir_name}_labels.csv\"))\n",
    "        #Number of classes.\n",
    "        self.n_classes = len(self.data['y'].unique())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        :return: The length of the training/testing dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[array, str]:\n",
    "        \"\"\"\n",
    "        Return the input and target at a specific index of the dataset.\n",
    "\n",
    "        :param idx: The index of the data to be returned.\n",
    "        :return: Key-value pair at the specified index.\n",
    "        \"\"\"\n",
    "\n",
    "        # Open corresponding Image\n",
    "        image = Image.open(os.path.join(os.getcwd(), self.data.loc[idx, 'file_name']))\n",
    "\n",
    "        # Retrieve the label\n",
    "        y = self.data.loc[idx, 'y']\n",
    "\n",
    "        # Transform the image if necessary.\n",
    "        if self.transform is not None:\n",
    "            image_ = self.transform(image)\n",
    "            image.close()\n",
    "        else:\n",
    "            image_ = array(image)\n",
    "            image.close()\n",
    "        return image_, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc720fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A training framework for classification tasks.\n",
    "\"\"\"\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple\n",
    "from os.path import join\n",
    "from os import getcwd\n",
    "\n",
    "from matplotlib.pyplot import subplots, show\n",
    "from numpy import sum \n",
    "from torch import argmax, device, cuda, save, load\n",
    "from torch.nn import Module\n",
    "from torch.nn.functional import softmax\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ClassificationModelTrainer:\n",
    "\n",
    "    def __init__(self, model: Module, training_set: Dataset, validation_set: Dataset,\n",
    "                batch_size: int, minimising_criterion: _Loss, optymiser: Optimizer) -> None:\n",
    "        \"\"\"\n",
    "        Initialise a classification model training module.\n",
    "\n",
    "        :param model: The modeltraining module.\n",
    "        :param training_set: The set of training data.\n",
    "        :param validation_set: The set of validation data.\n",
    "        :param batch_size: The barch  size for training.\n",
    "        :param minimising_criterion: The loss function.\n",
    "        :param optimiser: Thr algorithm to ferform minimisation task.\n",
    "        \"\"\"\n",
    "\n",
    "        self._device = device(\"cuda:0\" if cuda.is_available() else \"cpu\")\n",
    "        self._model = model.to(self._device)\n",
    "        self._train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "        self._validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True)\n",
    "        self._minimising_criterion = minimising_criterion\n",
    "        self._optimiser = optymiser\n",
    "        self.training_loss = []\n",
    "        self.validation_acc= []\n",
    "\n",
    "    def det_model(self) -> Module:\n",
    "        \"\"\"\n",
    "        Detter funcon for model.\n",
    "\n",
    "        :return: Return the trained model\n",
    "        \"\"\"\n",
    "        return self._model\n",
    "    \n",
    "    def train_model(self, n_epochs) -> None:\n",
    "        \"\"\"\n",
    "        Perform the model training.\n",
    "\n",
    "        :param n_epochs: The number of training epochs to run.\n",
    "        \"\"\"\n",
    "        # Setup the progress bar.\n",
    "        pbar = tqdm(total=n_epochs * (len(self._train_loader) + len(self._validation_loader)))\n",
    "        pbar.set_postfix({\n",
    "            \"TrainingLoss\": \"Not yet available\" if len(self.training_loss) == 0 else self.training_loss[-1],\n",
    "            \"Validation Accuracy\": \"Not yet available\" if len(self.validation_acc) == 0 else self.validation_acc[-1],\n",
    "            \"Epoch\": 1})\n",
    "\n",
    "        #Training through the epochs\n",
    "        for epoch in range(n_epochs):\n",
    "            loss_sublist = []\n",
    "\n",
    "            #Training process\n",
    "            for x,y in self._train_loader:\n",
    "                x,y = x.to(self._device), y.to(self._device)\n",
    "                self._model.train()\n",
    "                z = self._model(x)\n",
    "                loss = self._minimising_criterion(z, y)\n",
    "                loss_sublist.append(loss.data.item())\n",
    "                loss.backward()\n",
    "                self._optimiser.step()\n",
    "                self._optimiser.zero_grad()\n",
    "                pbar.update()\n",
    "            self.training_loss.append(sum(loss_sublist))\n",
    "\n",
    "            #Validation process\n",
    "            correct = 0\n",
    "            n_test = 0\n",
    "            for x_test, y_test in self._validation_loader:\n",
    "                x_test,y_test = x_test.to(self._device), y_test.to(self._device)\n",
    "                self._model.eval()\n",
    "                z = softmax(self._model(x_test), dim=1)\n",
    "                y_hat = argmax(z.data, dim=1)\n",
    "                correct += (y_hat == y_test).sum().item()\n",
    "                n_test += y_hat.shape[0]\n",
    "                pbar.update()\n",
    "            accuracy = correct / n_test\n",
    "            self.validation_acc.append(accuracy)\n",
    "            pbar.set_postfix({\n",
    "                \"Training Loss\": self.training_loss[-1],\n",
    "                \"Validation Accuracy\": self.validation_acc[-1],\n",
    "                \"Epoch\": n_epochs\n",
    "                })\n",
    "\n",
    "    def plot_training_stat(self):\n",
    "        \"\"\"\n",
    "        This function plots the training statistics the model trainer collected\n",
    "        throughout thw training process. Namely, they are\n",
    "\n",
    "        - Total training loss versis Iterations, and\n",
    "        - Validation Accuracy versus Iterations.\n",
    "\n",
    "        Thw two statistics are placed in the same plot, respectively in red and blue.\n",
    "        \"\"\"\n",
    "\n",
    "        #Plot Total training loss versus Iterations\n",
    "        fig, ax1 = subplots()\n",
    "        color = 'tab:red'\n",
    "        ax1.plot(self.training_loss, color=color)\n",
    "        ax1.set_xlabel('Iterations', color='black')\n",
    "        ax1.set_ylabel('Total Training Loss', color=color)\n",
    "        ax1.set_ylim(bottom = 0)\n",
    "        ax1.tick_params(axis='y', color=color)\n",
    "\n",
    "        #Plot valodation accuracy versus iterations\n",
    "        ax2 = ax1.twinx()\n",
    "        color = 'tab:blue'\n",
    "        ax2.plot(self.validation_acc, color=color)\n",
    "        ax2.set_ylabel('Validation Accuracy', color=color)\n",
    "        ax2.set_ylim(bottom = 0)\n",
    "        ax2.tick_params(axis='y', color=color)\n",
    "        ax2.set_ylim(0, 1)\n",
    "        fig.tight_layout()\n",
    "        show()\n",
    "\n",
    "    def test(self, testing_data: Dataset) -> float:\n",
    "        \"\"\"\n",
    "        This function tests the model's performance on a given dataset.\n",
    "\n",
    "        :patmtesting_data: The dataset to perform testing upon.\n",
    "        :return: Model's accuracy on the given testing data.\n",
    "        \"\"\"\n",
    "\n",
    "        _class = [\"Hot dog\", \"Not hot dog\"]\n",
    "        j = 0\n",
    "        total = 0\n",
    "        print(\"Here are a list of inaccurately classified results:\")\n",
    "        for x, y in DataLoader(dataset=testing_data, batch_size=1, shuffle=True):\n",
    "            x, y = x.to(self._device), y.to(self._device)\n",
    "            predicted = argmax(softmax(self._model(x.to(self._device)), dim=1), dim=1)\n",
    "            if predicted != y:\n",
    "                j += 1\n",
    "                print(f\"Actual: {_class[y.item()]}\\t\\tPredicted: {_class[predicted.item()]}\")\n",
    "                imshow(x[0])\n",
    "            total += 1\n",
    "        return 100 - 100*j/total\n",
    "    \n",
    "    def dump_to(self, file_name: str) -> None:\n",
    "        \"\"\"\n",
    "        This function dumps the trained model.\n",
    "\n",
    "        :param file_name: The directory to save state files.\n",
    "        \"\"\"\n",
    "        save_path = join(getcwd(), file_name)\n",
    "        save({\"mpdel_params\": self._model.state_dict(),\n",
    "              \"optimiser_stats\": self._optimiser.state_dict(),\n",
    "              \"acc\":self.validation_acc,\n",
    "              \"loss\": self.training_loss\n",
    "              }, save_path)\n",
    "    \n",
    "    def load_from(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        This function loads the dumped file back to the training framework\n",
    "\n",
    "        :param path: The path to the dumped file.\n",
    "        \"\"\"\n",
    "\n",
    "        state_dict = load(path, map_location=self._device)\n",
    "        self._model.load_state_dict(state_dict[\"model_params\"])\n",
    "        self._optimiser.load_state_dict(state_dict[\"optimiser_stats\"])\n",
    "        self.validation_acc = state_dict[\"acc\"]\n",
    "        self.training_loss = state_dict[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c913ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "composed = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a46d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = HotDogDataset('hotdognothotdogfull', transform = composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch import manual_seed\n",
    "\n",
    "manual_seed(0)\n",
    "training_size = int(len(dataset_full) * 0.7)\n",
    "validation_size = int(len(dataset_full) * 0.15)\n",
    "test_size = len(dataset_full) - training_size - validation_size\n",
    "training_set, validation_set, test_set = random_split(dataset=dataset_full, lengths=(training_size, validation_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size: train set\n",
    "batch_size = 50\n",
    "\n",
    "# Learning rate\n",
    "lr = 5e-3\n",
    "\n",
    "# Number epochs\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552739bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fa5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_classes = dataset_full.n_classes\n",
    "model.fc = Linear(512, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba084fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ClassificationModelTrainer(model, training_set, validation_set, batch_size, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c588c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get(f\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/build-a-hotdog-not-hotdog-classifier-guided-project/twenty-five-iters.pt\")\n",
    "f = open(os.path.join(os.getcwd(), \"./twenty-five-iters.pt\"), mode=\"wb+\")\n",
    "f.write(r.content)\n",
    "f.close()\n",
    "\n",
    "trainer.load_from(\"./twenty-five-iters.pt\")\n",
    "trainer.train_model(n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb32937",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_training_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = trainer.test(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The model reached an accuracy rate of {accuracy:.2f}% on images it has never seen before.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1a4c899fa19f7c38d4b04980e889ca9cf53cb5c59cb44354043cbb9f1c08df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
